{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313384e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install datasets ir_datasets rank_bm25 sentence_transformers keras langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d2c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8671123-011e-405f-984c-27c22af7e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from ir_datasets import load as load_ir\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7b68d-232c-49d1-9cc1-9a4f306255e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"parquet\", data_files=\"train-00000-of-00047.parquet\", split=\"train[:50]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6632da55-e762-4a3a-ac4d-95b594c42087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'])\n"
     ]
    }
   ],
   "source": [
    "print(ds[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17df55ea-497f-4104-85d6-01164d90b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['doc_source', 'filename', 'title', 'wiki_context'])\n"
     ]
    }
   ],
   "source": [
    "print(ds[0][\"entity_pages\"].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2526b32a-bc6f-402b-bd5b-a7c0fe119678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['description', 'filename', 'rank', 'title', 'url', 'search_context'])\n"
     ]
    }
   ],
   "source": [
    "print(ds[0][\"search_results\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5569c397-7aeb-4e58-8039-c57f238abc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed questions: 50\n",
      "Unique documents in corpus: 528\n",
      "Avg candidates per question: 10.76\n",
      "Avg gold docs per question: 1.66\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Limit for teaching purposes (you can increase)\n",
    "N = len(ds)  # or smaller, e.g., 50\n",
    "\n",
    "doc_texts = []        # all unique docs for FAISS\n",
    "doc_meta  = []        # optional metadata\n",
    "doc_key_to_id = {}    # map text -> index for deduplication\n",
    "\n",
    "q_gold = {}       # question idx -> set(doc_id) (gold)\n",
    "q_candidates = {} # question idx -> list(doc_id) (candidate pool)\n",
    "\n",
    "def add_doc(text, meta=None):\n",
    "    t = text.strip()\n",
    "    if not t:\n",
    "        return None\n",
    "    if t in doc_key_to_id:\n",
    "        return doc_key_to_id[t]\n",
    "    doc_id = len(doc_texts)\n",
    "    doc_texts.append(t)\n",
    "    doc_meta.append(meta)\n",
    "    doc_key_to_id[t] = doc_id\n",
    "    return doc_id\n",
    "\n",
    "for i in range(N):\n",
    "    item = ds[i]\n",
    "    \n",
    "    # --- Gold docs ---\n",
    "    gold_ids = set()\n",
    "    for txt in item[\"entity_pages\"][\"wiki_context\"]:\n",
    "        did = add_doc(txt, meta={\"type\":\"gold\"})\n",
    "        if did is not None:\n",
    "            gold_ids.add(did)\n",
    "    \n",
    "    # --- Candidate docs ---\n",
    "    cand_ids = []\n",
    "    for txt in item[\"search_results\"][\"search_context\"]:\n",
    "        did = add_doc(txt, meta={\"type\":\"candidate\"})\n",
    "        if did is not None:\n",
    "            cand_ids.append(did)\n",
    "    \n",
    "    # Ensure gold docs are in candidate list\n",
    "    for gid in list(gold_ids):\n",
    "        if gid not in cand_ids:\n",
    "            cand_ids.append(gid)\n",
    "    \n",
    "    q_gold[i] = gold_ids\n",
    "    q_candidates[i] = cand_ids\n",
    "\n",
    "# Summary\n",
    "print(\"Processed questions:\", N)\n",
    "print(\"Unique documents in corpus:\", len(doc_texts))\n",
    "avg_cands = sum(len(v) for v in q_candidates.values()) / max(1, N)\n",
    "avg_golds = sum(len(v) for v in q_gold.values()) / max(1, N)\n",
    "print(f\"Avg candidates per question: {avg_cands:.2f}\")\n",
    "print(f\"Avg gold docs per question: {avg_golds:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb7633-1c06-4221-bc89-fe433e42362e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd864aa-f8a2-4ffb-9f0a-1bab0b453f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate total tokens in candidate docs: 1532383\n",
      "Total candidate docs: 528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01131a13d9a042c5b5214eac2bd05233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to embed 528 docs (1532383 tokens approx): 51.51 seconds\n",
      "Time taken to add embeddings to FAISS index: 0.00 seconds\n",
      "FAISS index built with 528 documents\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 2a: Build embeddings for all candidate docs\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Count approximate tokens (split by space)\n",
    "num_tokens = sum(len(doc.split()) for doc in doc_texts)\n",
    "print(\"Approximate total tokens in candidate docs:\", num_tokens)\n",
    "print(\"Total candidate docs:\", len(doc_texts))\n",
    "\n",
    "# Measure time for embedding\n",
    "start_time = time.time()\n",
    "cand_embeddings = model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to embed {len(doc_texts)} docs ({num_tokens} tokens approx): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 2b: Build FAISS index\n",
    "start_index_time = time.time()\n",
    "embedding_dim = cand_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # L2 distance\n",
    "index.add(cand_embeddings)\n",
    "end_index_time = time.time()\n",
    "print(f\"Time taken to add embeddings to FAISS index: {end_index_time - start_index_time:.2f} seconds\")\n",
    "print(\"FAISS index built with\", index.ntotal, \"documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f373b087-c5ec-40af-a068-1c1f047c58cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was President when the first Peanuts cartoon was published?\n",
      "Gold doc IDs: {0}\n",
      "\n",
      "Top-k retrieved doc IDs: [5 1 4 0 3]\n",
      "\n",
      "Rank 1 - Doc ID 5 ❌:\n",
      "A Brief History of Charles Schulz's 'Peanuts' Comic Strip - TIME Follow @TIME When Alex Davis was 2 years old, he pointed to a drawing his father had done and exclaimed, \"Snoopy!\" The problem: his father was Jim Davis, the creator of Garfield, and the picture was of the cat he made famous. Charles S ...\n",
      "\n",
      "Rank 2 - Doc ID 1 ❌:\n",
      "Peanuts | Peanuts Wiki | Fandom powered by Wikia Charles M. Schulz drawing Snoopy . Peanuts is a syndicated daily and Sunday comic strip written and illustrated by Charles M. Schulz , which ran from October 2, 1950, to February 13, 2000 (the day after Schulz's death). In total 17,897 different Peanu ...\n",
      "\n",
      "Rank 3 - Doc ID 4 ❌:\n",
      "Peanuts by Charles Schulz  | Read Comic Strips at GoComics.com Share Link Explore Peanuts ...\n",
      "\n",
      "Rank 4 - Doc ID 0 ✅ GOLD:\n",
      "Peanuts is a syndicated daily and Sunday American comic strip written and illustrated by Charles M. Schulz, which ran from October 2, 1950, to February 13, 2000, continuing in reruns afterward. The strip is the most popular and influential in the history of comic strips, with 17,897 strips published ...\n",
      "\n",
      "Rank 5 - Doc ID 3 ❌:\n",
      "Frequently Asked Questions - Charles M. Schulz Museum Charles M. Schulz Museum The Peanuts Comic Strip Why is the comic strip named Peanuts? Originally, Charles Schulz named his strip Li’l Folks, but when it became syndicated in 1950 by United Feature Syndicate, there was concern about possible copy ...\n",
      "\n",
      "Metrics for this question:\n",
      "Precision@5: 0.200\n",
      "Recall@5: 1.000\n",
      "Reciprocal Rank (RR): 0.250\n"
     ]
    }
   ],
   "source": [
    "# Pick one question\n",
    "i = 0\n",
    "question = ds[i][\"question\"]\n",
    "gold_ids = q_gold[i]  # set of gold doc IDs\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Gold doc IDs:\", gold_ids)\n",
    "\n",
    "# Embed the question\n",
    "q_emb = model.encode(question, convert_to_numpy=True)\n",
    "\n",
    "# Retrieve top-k docs\n",
    "top_k = 5\n",
    "D, I = index.search(np.expand_dims(q_emb, axis=0), top_k)\n",
    "retrieved_ids = I[0]\n",
    "\n",
    "print(\"\\nTop-k retrieved doc IDs:\", retrieved_ids)\n",
    "\n",
    "# Show retrieved snippets and indicate gold\n",
    "for rank, doc_id in enumerate(retrieved_ids, start=1):\n",
    "    snippet = doc_texts[doc_id][:300].replace(\"\\n\", \" \")\n",
    "    is_gold = \"✅ GOLD\" if doc_id in gold_ids else \"❌\"\n",
    "    print(f\"\\nRank {rank} - Doc ID {doc_id} {is_gold}:\\n{snippet} ...\")\n",
    "\n",
    "# Compute metrics for this single question\n",
    "precision = len(gold_ids & set(retrieved_ids)) / top_k\n",
    "recall = len(gold_ids & set(retrieved_ids)) / max(1, len(gold_ids))\n",
    "rr = 0\n",
    "for rank, doc_id in enumerate(retrieved_ids):\n",
    "    if doc_id in gold_ids:\n",
    "        rr = 1 / (rank + 1)\n",
    "        break\n",
    "\n",
    "print(f\"\\nMetrics for this question:\")\n",
    "print(f\"Precision@{top_k}: {precision:.3f}\")\n",
    "print(f\"Recall@{top_k}: {recall:.3f}\")\n",
    "print(f\"Reciprocal Rank (RR): {rr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec90797-9e80-4e0b-80dd-c9a4e7b02b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2467fd-63e7-4bf0-9888-1241450af89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea6f586-ad91-4362-bb9e-d3ed530f3641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked top-k doc IDs: [1, 0, 5, 3, 4]\n",
      "\n",
      "Rank 1 - Doc ID 1 ❌:\n",
      "Peanuts | Peanuts Wiki | Fandom powered by Wikia Charles M. Schulz drawing Snoopy . Peanuts is a syndicated daily and Sunday comic strip written and illustrated by Charles M. Schulz , which ran from October 2, 1950, to February 13, 2000 (the day after Schulz's death). In total 17,897 different Peanu ...\n",
      "\n",
      "Rank 2 - Doc ID 0 ✅ GOLD:\n",
      "Peanuts is a syndicated daily and Sunday American comic strip written and illustrated by Charles M. Schulz, which ran from October 2, 1950, to February 13, 2000, continuing in reruns afterward. The strip is the most popular and influential in the history of comic strips, with 17,897 strips published ...\n",
      "\n",
      "Rank 3 - Doc ID 5 ❌:\n",
      "A Brief History of Charles Schulz's 'Peanuts' Comic Strip - TIME Follow @TIME When Alex Davis was 2 years old, he pointed to a drawing his father had done and exclaimed, \"Snoopy!\" The problem: his father was Jim Davis, the creator of Garfield, and the picture was of the cat he made famous. Charles S ...\n",
      "\n",
      "Rank 4 - Doc ID 3 ❌:\n",
      "Frequently Asked Questions - Charles M. Schulz Museum Charles M. Schulz Museum The Peanuts Comic Strip Why is the comic strip named Peanuts? Originally, Charles Schulz named his strip Li’l Folks, but when it became syndicated in 1950 by United Feature Syndicate, there was concern about possible copy ...\n",
      "\n",
      "Rank 5 - Doc ID 4 ❌:\n",
      "Peanuts by Charles Schulz  | Read Comic Strips at GoComics.com Share Link Explore Peanuts ...\n",
      "\n",
      "Metrics after reranking:\n",
      "Precision@5: 0.200\n",
      "Recall@5: 1.000\n",
      "Reciprocal Rank (RR): 0.500\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load cross-encoder (fine-tuned for relevance / QA)\n",
    "cross_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# Example: single question\n",
    "i = 0\n",
    "question = ds[i][\"question\"]\n",
    "gold_ids = q_gold[i]\n",
    "\n",
    "# Step 1: retrieve top-k using FAISS\n",
    "top_k = 5\n",
    "q_emb = model.encode(question, convert_to_numpy=True)  # use your sentence-transformer\n",
    "D, I = index.search(np.expand_dims(q_emb, axis=0), top_k)\n",
    "retrieved_ids = I[0]\n",
    "\n",
    "# Step 2: prepare pairs for cross-encoder scoring\n",
    "pairs = [[question, doc_texts[doc_id]] for doc_id in retrieved_ids]\n",
    "\n",
    "# Step 3: compute relevance scores\n",
    "scores = cross_model.predict(pairs)\n",
    "\n",
    "# Step 4: sort by score (descending)\n",
    "sorted_idx = np.argsort(scores)[::-1]\n",
    "reranked_ids = [retrieved_ids[idx] for idx in sorted_idx]\n",
    "\n",
    "# Step 5: display reranked docs and compute metrics\n",
    "print(\"Reranked top-k doc IDs:\", reranked_ids)\n",
    "for rank, doc_id in enumerate(reranked_ids, start=1):\n",
    "    snippet = doc_texts[doc_id][:300].replace(\"\\n\", \" \")\n",
    "    is_gold = \"✅ GOLD\" if doc_id in gold_ids else \"❌\"\n",
    "    print(f\"\\nRank {rank} - Doc ID {doc_id} {is_gold}:\\n{snippet} ...\")\n",
    "\n",
    "# Step 6: compute metrics after reranking\n",
    "precision = len(gold_ids & set(reranked_ids)) / top_k\n",
    "recall = len(gold_ids & set(reranked_ids)) / max(1, len(gold_ids))\n",
    "rr = 0\n",
    "for rank, doc_id in enumerate(reranked_ids):\n",
    "    if doc_id in gold_ids:\n",
    "        rr = 1 / (rank + 1)\n",
    "        break\n",
    "\n",
    "print(f\"\\nMetrics after reranking:\")\n",
    "print(f\"Precision@{top_k}: {precision:.3f}\")\n",
    "print(f\"Recall@{top_k}: {recall:.3f}\")\n",
    "print(f\"Reciprocal Rank (RR): {rr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606abe08-f01c-4d38-add3-27e60d2f922d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d79798-c108-4681-89e1-63a14bbe43a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b969b018-6813-43b8-ad33-c93b755cf9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Initialize Chroma client with new configuration\n",
    "client = chromadb.Client(Settings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf2a476-6f68-4e7a-af86-df1390681b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma collection 'candidate_docs' created with 528 documents.\n"
     ]
    }
   ],
   "source": [
    "# Install Chroma if not already\n",
    "# pip install chromadb\n",
    "\n",
    "\n",
    "\n",
    "# Create a collection\n",
    "collection_name = \"candidate_docs\"\n",
    "if collection_name in [c.name for c in client.list_collections()]:\n",
    "    client.delete_collection(collection_name)\n",
    "collection = client.create_collection(name=collection_name)\n",
    "\n",
    "# Add documents + embeddings to Chroma\n",
    "ids = [str(i) for i in range(len(doc_texts))]  # simple string IDs\n",
    "metadatas = [{\"source\": \"candidate_doc\"} for _ in doc_texts]  # optional metadata\n",
    "\n",
    "collection.add(\n",
    "    documents=doc_texts,\n",
    "    embeddings=cand_embeddings.tolist(),  # Chroma expects list of lists\n",
    "    ids=ids,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "print(f\"Chroma collection '{collection_name}' created with {len(doc_texts)} documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9fa4e3a-44b1-44d0-a3af-4db6be2f1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was President when the first Peanuts cartoon was published?\n",
      "Gold doc snippet: Peanuts is a syndicated daily and Sunday American comic strip written and illustrated by Charles M. Schulz, which ran from October 2, 1950, to February 13, 2000, continuing in reruns afterward. The strip is the most popular and influential in the history of comic strips, with 17,897 strips published ...\n",
      "\n",
      "Top-k retrieved docs:\n",
      "Rank 1 - Doc ID 5 ❌:\n",
      "A Brief History of Charles Schulz's 'Peanuts' Comic Strip - TIME Follow @TIME When Alex Davis was 2 years old, he pointed to a drawing his father had done and exclaimed, \"Snoopy!\" The problem: his father was Jim Davis, the creator of Garfield, and the picture was of the cat he made famous. Charles Schulz's black-and-white dog is so beloved, though, that a lasagna-loving cat can't even compete. Saturday, Oct. 2, marks 60 years since Schulz's first Peanuts strip hit newspapers. Since then, Snoopy,\n",
      "\n",
      "Rank 2 - Doc ID 1 ❌:\n",
      "Peanuts | Peanuts Wiki | Fandom powered by Wikia Charles M. Schulz drawing Snoopy . Peanuts is a syndicated daily and Sunday comic strip written and illustrated by Charles M. Schulz , which ran from October 2, 1950, to February 13, 2000 (the day after Schulz's death). In total 17,897 different Peanuts strips were published. The strip was one of the most popular and influential in the history of the medium, and considered the most beloved comic strips of all time. It was \"arguably the longest sto\n",
      "\n",
      "Rank 3 - Doc ID 4 ❌:\n",
      "Peanuts by Charles Schulz  | Read Comic Strips at GoComics.com Share Link Explore Peanuts\n",
      "\n",
      "Rank 4 - Doc ID 0 ✅ GOLD:\n",
      "Peanuts is a syndicated daily and Sunday American comic strip written and illustrated by Charles M. Schulz, which ran from October 2, 1950, to February 13, 2000, continuing in reruns afterward. The strip is the most popular and influential in the history of comic strips, with 17,897 strips published in all, making it \"arguably the longest story ever told by one human being\".  At its peak, Peanuts ran in over 2,600 newspapers, with a readership of 355 million in 75 countries, and was translated i\n",
      "\n",
      "Rank 5 - Doc ID 3 ❌:\n",
      "Frequently Asked Questions - Charles M. Schulz Museum Charles M. Schulz Museum The Peanuts Comic Strip Why is the comic strip named Peanuts? Originally, Charles Schulz named his strip Li’l Folks, but when it became syndicated in 1950 by United Feature Syndicate, there was concern about possible copyright infringement with a cartoon called Little Folks by Tack Knight that had been published in the 1930s. Schulz suggested Charlie Brown or Good Ol’ Charlie Brown, but the syndicate decided upon Pean\n",
      "\n",
      "Metrics after retrieval:\n",
      "Precision@5: 0.200\n",
      "Recall@5: 1.000\n",
      "Reciprocal Rank (RR): 0.250\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Single Question Retrieval Demo -----------------\n",
    "sample = ds[0]\n",
    "question = sample[\"question\"]\n",
    "gold_docs = set(sample[\"entity_pages\"][\"wiki_context\"])  # ground truth docs\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Gold doc snippet:\", list(gold_docs)[0][:300], \"...\")\n",
    "\n",
    "# Embed question\n",
    "query_emb = model.encode(question).tolist()\n",
    "\n",
    "# Retrieve top-k from Chroma\n",
    "top_k = 5\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_emb],\n",
    "    n_results=top_k\n",
    ")\n",
    "\n",
    "retrieved_docs = results['documents'][0]\n",
    "retrieved_ids = results['ids'][0]  # get document IDs from Chroma\n",
    "\n",
    "# Print ranked docs with gold check\n",
    "print(\"\\nTop-k retrieved docs:\")\n",
    "for rank, (doc_id, doc) in enumerate(zip(retrieved_ids, retrieved_docs), start=1):\n",
    "    check = \"✅ GOLD\" if doc in gold_docs else \"❌\"\n",
    "    snippet = doc[:500].replace(\"\\n\", \" \")  # first 500 chars, remove line breaks\n",
    "    print(f\"Rank {rank} - Doc ID {doc_id} {check}:\\n{snippet}\\n\")\n",
    "\n",
    "# Compute metrics\n",
    "retrieved_set = set(retrieved_docs)\n",
    "precision = len(gold_docs & retrieved_set) / top_k\n",
    "recall = len(gold_docs & retrieved_set) / max(1, len(gold_docs))\n",
    "\n",
    "rr = 0\n",
    "for rank, doc in enumerate(retrieved_docs):\n",
    "    if doc in gold_docs:\n",
    "        rr = 1 / (rank + 1)\n",
    "        break\n",
    "\n",
    "print(\"Metrics after retrieval:\")\n",
    "print(f\"Precision@{top_k}: {precision:.3f}\")\n",
    "print(f\"Recall@{top_k}: {recall:.3f}\")\n",
    "print(f\"Reciprocal Rank (RR): {rr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd607bb1-3104-464a-91db-ca17af6de733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was President when the first Peanuts cartoon was published?\n",
      "Gold doc snippet: Peanuts is a syndicated daily and Sunday American comic strip written and illustrated by Charles M. Schulz, which ran from October 2, 1950, to February 13, 2000, continuing in reruns afterward. The strip is the most popular and influential in the history of comic strips, with 17,897 strips published ...\n",
      "\n",
      "Reranked top-k docs:\n",
      "Rank 1 - Doc ID 1 ❌:\n",
      "Peanuts | Peanuts Wiki | Fandom powered by Wikia Charles M. Schulz drawing Snoopy . Peanuts is a syndicated daily and Sunday comic strip written and illustrated by Charles M. Schulz , which ran from October 2, 1950, to February 13, 2000 (the day after Schulz's death). In total 17,897 different Peanuts strips were published. The strip was one of the most popular and influential in the history of the medium, and considered the most beloved comic strips of all time. It was \"arguably the longest sto\n",
      "\n",
      "Rank 2 - Doc ID 0 ✅ GOLD:\n",
      "Peanuts is a syndicated daily and Sunday American comic strip written and illustrated by Charles M. Schulz, which ran from October 2, 1950, to February 13, 2000, continuing in reruns afterward. The strip is the most popular and influential in the history of comic strips, with 17,897 strips published in all, making it \"arguably the longest story ever told by one human being\".  At its peak, Peanuts ran in over 2,600 newspapers, with a readership of 355 million in 75 countries, and was translated i\n",
      "\n",
      "Rank 3 - Doc ID 5 ❌:\n",
      "A Brief History of Charles Schulz's 'Peanuts' Comic Strip - TIME Follow @TIME When Alex Davis was 2 years old, he pointed to a drawing his father had done and exclaimed, \"Snoopy!\" The problem: his father was Jim Davis, the creator of Garfield, and the picture was of the cat he made famous. Charles Schulz's black-and-white dog is so beloved, though, that a lasagna-loving cat can't even compete. Saturday, Oct. 2, marks 60 years since Schulz's first Peanuts strip hit newspapers. Since then, Snoopy,\n",
      "\n",
      "Rank 4 - Doc ID 3 ❌:\n",
      "Frequently Asked Questions - Charles M. Schulz Museum Charles M. Schulz Museum The Peanuts Comic Strip Why is the comic strip named Peanuts? Originally, Charles Schulz named his strip Li’l Folks, but when it became syndicated in 1950 by United Feature Syndicate, there was concern about possible copyright infringement with a cartoon called Little Folks by Tack Knight that had been published in the 1930s. Schulz suggested Charlie Brown or Good Ol’ Charlie Brown, but the syndicate decided upon Pean\n",
      "\n",
      "Rank 5 - Doc ID 4 ❌:\n",
      "Peanuts by Charles Schulz  | Read Comic Strips at GoComics.com Share Link Explore Peanuts\n",
      "\n",
      "Metrics after reranking:\n",
      "Precision@5: 0.200\n",
      "Recall@5: 1.000\n",
      "Reciprocal Rank (RR): 0.500\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# ----------------- Single Question Retrieval + Rerank -----------------\n",
    "sample = ds[0]\n",
    "question = sample[\"question\"]\n",
    "gold_docs = set(sample[\"entity_pages\"][\"wiki_context\"])  # ground truth docs\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Gold doc snippet:\", list(gold_docs)[0][:300], \"...\")\n",
    "\n",
    "# Embed question\n",
    "query_emb = model.encode(question).tolist()\n",
    "\n",
    "# Retrieve top-k from Chroma\n",
    "top_k = 5\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_emb],\n",
    "    n_results=top_k\n",
    ")\n",
    "\n",
    "retrieved_docs = results['documents'][0]\n",
    "retrieved_ids = results['ids'][0]  # doc IDs\n",
    "\n",
    "# ----------------- Rerank with Cross-Encoder -----------------\n",
    "cross_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "pairs = [[question, doc] for doc in retrieved_docs]\n",
    "scores = cross_model.predict(pairs)\n",
    "\n",
    "# Sort by scores descending\n",
    "reranked = sorted(zip(scores, retrieved_ids, retrieved_docs), reverse=True)\n",
    "reranked_scores, reranked_ids, reranked_docs = zip(*reranked)\n",
    "\n",
    "# Print reranked top-k\n",
    "print(\"\\nReranked top-k docs:\")\n",
    "for rank, (doc_id, doc) in enumerate(zip(reranked_ids, reranked_docs), start=1):\n",
    "    check = \"✅ GOLD\" if doc in gold_docs else \"❌\"\n",
    "    snippet = doc[:500].replace(\"\\n\", \" \")\n",
    "    print(f\"Rank {rank} - Doc ID {doc_id} {check}:\\n{snippet}\\n\")\n",
    "\n",
    "# ----------------- Compute Metrics -----------------\n",
    "retrieved_set = set(reranked_docs)\n",
    "precision = len(gold_docs & retrieved_set) / top_k\n",
    "recall = len(gold_docs & retrieved_set) / max(1, len(gold_docs))\n",
    "\n",
    "rr = 0\n",
    "for rank, doc in enumerate(reranked_docs):\n",
    "    if doc in gold_docs:\n",
    "        rr = 1 / (rank + 1)\n",
    "        break\n",
    "\n",
    "print(\"Metrics after reranking:\")\n",
    "print(f\"Precision@{top_k}: {precision:.3f}\")\n",
    "print(f\"Recall@{top_k}: {recall:.3f}\")\n",
    "print(f\"Reciprocal Rank (RR): {rr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587229f-4b98-4f46-b703-2e6b37880d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc226a3d-80ad-4bbd-821e-3b684c112044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658066b-84bf-4ad2-903d-f73d1c87d958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae1334-5e90-4c14-b631-a51bd5dd870b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861414c-6cfc-4e0f-a96d-8cbd23861bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bc71a-a2b6-4e53-a6a9-786538005a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7ec7a-0e5d-472d-a94e-4abcbf8ac3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45cf50-6346-4943-89fa-163f1e180b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30640446-3ecf-478d-85c6-f0e417750ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934b076-fe1e-4b32-8c42-2699b472a961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40b934-b67c-4a5e-9b2d-d14160e1190c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef6a5d3-8670-4b51-8e2b-353915d2cbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910e790-7782-454d-b8b5-090540fca825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e2321-b52d-4f79-af22-afd8d6bb4f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
